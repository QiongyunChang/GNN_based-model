{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d821a4af-9663-469a-bfad-8784eaea4c0e",
   "metadata": {},
   "source": [
    "# BERTGCN with  PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a290fd-a62a-418f-a9f9-594125ceadb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2005.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# data= pd.read_csv(\"../dataset/yelp/yelp_over512.csv\",names=['label','text'])\n",
    "data= pd.read_csv(\"../dataset/IMDB/IMDB_over512.csv\",names=['label','text'])\n",
    "\n",
    "print(len(data['label'])*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82df7e8-0c5d-409c-88ca-3a522a7beed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#dataset_name = 'own'\n",
    "#sentences = ['Would you like a plain sweater or something else?', 'Great. We have some very nice wool slacks over here. Would you like to take a look?']\n",
    "#labels = ['Yes' , 'No' ]\n",
    "#train_or_test_list = ['train', 'test']\n",
    "import pandas as pd\n",
    "# data= pd.read_csv(\"../dataset/20ng/20ng_over512.csv\", names = [\"label\", \"text\"])\n",
    "# data= pd.read_csv(\"../dataset/hyper/hy512.csv\",names=['label','text'])\n",
    "# data= pd.read_csv(\"../dataset/yelp/yelp_over512.csv\",names=['label','text'])\n",
    "\n",
    "data= pd.read_csv(\"../dataset/IMDB/IMDB_over512.csv\",names=['label','text'])\n",
    "LE = LabelEncoder()\n",
    "data['label'] = LE.fit_transform(data['label'])\n",
    "sentences = []\n",
    "labels = []\n",
    "train_or_test_list = []\n",
    "for index,  label,text in data.itertuples():\n",
    "  sentences.append(text)\n",
    "  labels.append(label)\n",
    "  train_or_test_list.append('train' if index < 2005 else 'test')\n",
    "dataset_name = 'imdb'\n",
    "\n",
    "\n",
    "meta_data_list = []\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    meta = str(i) + '\\t' + train_or_test_list[i] + '\\t' + str(labels[i])\n",
    "    meta_data_list.append(meta)\n",
    "\n",
    "meta_data_str = '\\n'.join(meta_data_list)\n",
    "\n",
    "f = open( 'data/ '+ dataset_name + '.txt', 'w')\n",
    "f.write(meta_data_str)\n",
    "f.close()\n",
    "\n",
    "#corpus_str = '\\n'.join(sentences)\n",
    "corpus_str = '\\n'.join([str(i) for i in sentences])\n",
    "\n",
    "f = open('data/corpus/' + dataset_name + '.txt', 'w')\n",
    "f.write(corpus_str)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef7bba84-a63a-4490-9774-fc7b3fe2bdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/nm6104054/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "dataset = 'imdb'\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "remove_limit = 5\n",
    "data= pd.read_csv(\"../dataset/IMDB/IMDB_over512.csv\",names=['label','text'])\n",
    "\n",
    "# data= pd.read_csv(\"../dataset/20ng/20ng_over512.csv\", names = [\"label\", \"text\"])\n",
    "# data= pd.read_csv(\"../dataset/hyper/hy512.csv\",names=['label','text'])\n",
    "sentences = list(data['text'])\n",
    "\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "# original_word_freq = {}  # to remove rare words\n",
    "# fi = open('data/corpus/clean_' + dataset + '.txt', 'w', encoding=\"utf-8\")\n",
    "# for sentence in sentences:\n",
    "#     temp = clean_str(sentence)\n",
    "#     fi.write(temp)\n",
    "#     fi.close()\n",
    "with open('data/corpus/' + dataset + '.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    for sentence in sentences:\n",
    "        temp = clean_str(sentence)\n",
    "        f.write(temp+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e18b60f1-762d-4d45-bfb3-b391a4779a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/' + dataset + '.txt', 'r', encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c726f5-ebef-4bd9-bfea-76838ce94f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 300) (1350, 2) (2511, 300) (2511, 2) (27026, 300) (27026, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = 'imdb'\n",
    "# data= pd.read_csv(\"../dataset/20ng/20ng_over512.csv\", names = [\"label\", \"text\"])\n",
    "# data= pd.read_csv(\"../dataset/yelp/yelp_over512.csv\",names=['label','text'])\n",
    "data= pd.read_csv(\"../dataset/IMDB/IMDB_over512.csv\",names=['label','text'])\n",
    "\n",
    "# data= pd.read_csv(\"../dataset/hyper/hy512.csv\",names=['label','text'])\n",
    "# LE = LabelEncoder()\n",
    "data['label'] = LE.fit_transform(data['label'])\n",
    "sentences = []\n",
    "labels = []\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "word_embeddings_dim = 300\n",
    "word_vector_map = {}\n",
    "\n",
    "doc_name_list = []\n",
    "doc_train_list = []\n",
    "doc_test_list = []\n",
    "\n",
    "f = open('data/' + dataset + '.txt', 'r', encoding=\"utf-8\")\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    doc_name_list.append(line.strip())\n",
    "    temp = line.split(\"\\t\")\n",
    "    if temp[1].find('test') != -1:\n",
    "        doc_test_list.append(line.strip())\n",
    "    elif temp[1].find('train') != -1:\n",
    "        doc_train_list.append(line.strip())\n",
    "f.close()\n",
    "\n",
    "doc_content_list = []\n",
    "f = open('data/corpus/' + dataset + '.txt', 'r', encoding=\"utf-8\")\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    doc_content_list.append(line.strip())\n",
    "f.close()\n",
    "\n",
    "train_ids = []\n",
    "for train_name in doc_train_list:\n",
    "    train_id = doc_name_list.index(train_name)\n",
    "    train_ids.append(train_id)\n",
    "random.shuffle(train_ids)\n",
    "\n",
    "train_ids_str = '\\n'.join(str(index) for index in train_ids)\n",
    "f = open('data/' + dataset + '.train.index', 'w')\n",
    "f.write(train_ids_str)\n",
    "f.close()\n",
    "\n",
    "test_ids = []\n",
    "for test_name in doc_test_list:\n",
    "    test_id = doc_name_list.index(test_name)\n",
    "    test_ids.append(test_id)\n",
    "random.shuffle(test_ids)\n",
    "\n",
    "test_ids_str = '\\n'.join(str(index) for index in test_ids)\n",
    "f = open('data/' + dataset + '.test.index', 'w')\n",
    "f.write(test_ids_str)\n",
    "f.close()\n",
    "\n",
    "shuffle_doc_name_list = []\n",
    "shuffle_doc_words_list = []\n",
    "ids = train_ids + test_ids\n",
    "for id in ids:\n",
    "    shuffle_doc_name_list.append(doc_name_list[int(id)])\n",
    "    shuffle_doc_words_list.append(doc_content_list[int(id)])\n",
    "shuffle_doc_name_str = '\\n'.join(shuffle_doc_name_list)\n",
    "shuffle_doc_words_str = '\\n'.join(shuffle_doc_words_list)\n",
    "\n",
    "f = open('data/' + dataset + '_shuffle.txt', 'w', encoding=\"utf-8\")\n",
    "f.write(shuffle_doc_name_str)\n",
    "f.close()\n",
    "\n",
    "f = open('data/corpus/' + dataset + '_shuffle.txt', 'w', encoding=\"utf-8\")\n",
    "f.write(shuffle_doc_words_str)\n",
    "f.close()\n",
    "\n",
    "word_freq = {}\n",
    "word_set = set()\n",
    "for doc_words in shuffle_doc_words_list:\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    for word in words:\n",
    "        word_set.add(word)\n",
    "        if word in word_freq:\n",
    "            word_freq[word] += 1\n",
    "        else:\n",
    "            word_freq[word] = 1\n",
    "\n",
    "vocab = list(word_set)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_doc_list = {}\n",
    "\n",
    "for i in range(len(shuffle_doc_words_list)):\n",
    "    doc_words = shuffle_doc_words_list[i]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    appeared = set()\n",
    "    for word in words:\n",
    "        if word in appeared:\n",
    "            continue\n",
    "        if word in word_doc_list:\n",
    "            doc_list = word_doc_list[word]\n",
    "            doc_list.append(i)\n",
    "            word_doc_list[word] = doc_list\n",
    "        else:\n",
    "            word_doc_list[word] = [i]\n",
    "        appeared.add(word)\n",
    "\n",
    "word_doc_freq = {}\n",
    "for word, doc_list in word_doc_list.items():\n",
    "    word_doc_freq[word] = len(doc_list)\n",
    "\n",
    "word_id_map = {}\n",
    "for i in range(vocab_size):\n",
    "    word_id_map[vocab[i]] = i\n",
    "\n",
    "vocab_str = '\\n'.join(vocab)\n",
    "\n",
    "f = open('data/corpus/' + dataset + '_vocab.txt', 'w',encoding=\"utf-8\")\n",
    "f.write(vocab_str)\n",
    "f.close()\n",
    "\n",
    "label_set = set()\n",
    "for doc_meta in shuffle_doc_name_list:\n",
    "    temp = doc_meta.split('\\t')\n",
    "    label_set.add(temp[2])\n",
    "label_list = list(label_set)\n",
    "\n",
    "label_list_str = '\\n'.join(label_list)\n",
    "f = open('data/corpus/' + dataset + '_labels.txt', 'w',encoding=\"utf-8\")\n",
    "f.write(label_list_str)\n",
    "f.close()\n",
    "\n",
    "train_size = len(train_ids)\n",
    "val_size = int(0.1 * train_size)\n",
    "real_train_size = train_size - val_size\n",
    "\n",
    "real_train_doc_names = shuffle_doc_name_list[:real_train_size]\n",
    "real_train_doc_names_str = '\\n'.join(real_train_doc_names)\n",
    "\n",
    "f = open('data/' + dataset + '.real_train.name', 'w',encoding=\"utf-8\")\n",
    "f.write(real_train_doc_names_str)\n",
    "f.close()\n",
    "\n",
    "row_x = []\n",
    "col_x = []\n",
    "data_x = []\n",
    "\n",
    "for i in range(real_train_size):\n",
    "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
    "    doc_words = shuffle_doc_words_list[i]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    doc_len = len(words)\n",
    "    for word in words:\n",
    "        if word in word_vector_map:\n",
    "            word_vector = word_vector_map[word]\n",
    "            doc_vec = doc_vec + np.array(word_vector)\n",
    "\n",
    "    for j in range(word_embeddings_dim):\n",
    "        row_x.append(i)\n",
    "        col_x.append(j)\n",
    "        data_x.append(doc_vec[j] / doc_len)\n",
    "        \n",
    "x = sp.csr_matrix((data_x, (row_x, col_x)), shape=(\n",
    "    real_train_size, word_embeddings_dim))\n",
    "\n",
    "y = []\n",
    "for i in range(real_train_size):\n",
    "    doc_meta = shuffle_doc_name_list[i]\n",
    "    temp = doc_meta.split('\\t')\n",
    "    label = temp[2]\n",
    "    one_hot = [0 for l in range(len(label_list))]\n",
    "    label_index = label_list.index(label)\n",
    "    one_hot[label_index] = 1\n",
    "    y.append(one_hot)\n",
    "y = np.array(y)\n",
    "\n",
    "test_size = len(test_ids)\n",
    "\n",
    "row_tx = []\n",
    "col_tx = []\n",
    "data_tx = []\n",
    "for i in range(test_size):\n",
    "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
    "    doc_words = shuffle_doc_words_list[i + train_size]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    doc_len = len(words)\n",
    "    for word in words:\n",
    "        if word in word_vector_map:\n",
    "            word_vector = word_vector_map[word]\n",
    "            doc_vec = doc_vec + np.array(word_vector)\n",
    "\n",
    "    for j in range(word_embeddings_dim):\n",
    "        row_tx.append(i)\n",
    "        col_tx.append(j)\n",
    "        data_tx.append(doc_vec[j] / doc_len)\n",
    "\n",
    "tx = sp.csr_matrix((data_tx, (row_tx, col_tx)),\n",
    "                   shape=(test_size, word_embeddings_dim))\n",
    "\n",
    "ty = []\n",
    "for i in range(test_size):\n",
    "    doc_meta = shuffle_doc_name_list[i + train_size]\n",
    "    temp = doc_meta.split('\\t')\n",
    "    label = temp[2]\n",
    "    one_hot = [0 for l in range(len(label_list))]\n",
    "    label_index = label_list.index(label)\n",
    "    one_hot[label_index] = 1\n",
    "    ty.append(one_hot)\n",
    "ty = np.array(ty)\n",
    "\n",
    "word_vectors = np.random.uniform(-0.01, 0.01, (vocab_size, word_embeddings_dim))\n",
    "\n",
    "for i in range(len(vocab)):\n",
    "    word = vocab[i]\n",
    "    if word in word_vector_map:\n",
    "        vector = word_vector_map[word]\n",
    "        word_vectors[i] = vector\n",
    "\n",
    "row_allx = []\n",
    "col_allx = []\n",
    "data_allx = []\n",
    "\n",
    "for i in range(train_size):\n",
    "    doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
    "    doc_words = shuffle_doc_words_list[i]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    doc_len = len(words)\n",
    "    for word in words:\n",
    "        if word in word_vector_map:\n",
    "            word_vector = word_vector_map[word]\n",
    "            doc_vec = doc_vec + np.array(word_vector)\n",
    "\n",
    "    for j in range(word_embeddings_dim):\n",
    "        row_allx.append(int(i))\n",
    "        col_allx.append(j)\n",
    "        data_allx.append(doc_vec[j] / doc_len)\n",
    "for i in range(vocab_size):\n",
    "    for j in range(word_embeddings_dim):\n",
    "        row_allx.append(int(i + train_size))\n",
    "        col_allx.append(j)\n",
    "        data_allx.append(word_vectors.item((i, j)))\n",
    "\n",
    "\n",
    "row_allx = np.array(row_allx)\n",
    "col_allx = np.array(col_allx)\n",
    "data_allx = np.array(data_allx)\n",
    "\n",
    "allx = sp.csr_matrix(\n",
    "    (data_allx, (row_allx, col_allx)), shape=(train_size + vocab_size, word_embeddings_dim))\n",
    "\n",
    "ally = []\n",
    "for i in range(train_size):\n",
    "    doc_meta = shuffle_doc_name_list[i]\n",
    "    temp = doc_meta.split('\\t')\n",
    "    label = temp[2]\n",
    "    one_hot = [0 for l in range(len(label_list))]\n",
    "    label_index = label_list.index(label)\n",
    "    one_hot[label_index] = 1\n",
    "    ally.append(one_hot)\n",
    "\n",
    "for i in range(vocab_size):\n",
    "    one_hot = [0 for l in range(len(label_list))]\n",
    "    ally.append(one_hot)\n",
    "\n",
    "ally = np.array(ally)\n",
    "\n",
    "print(x.shape, y.shape, tx.shape, ty.shape, allx.shape, ally.shape)\n",
    "\n",
    "window_size = 20\n",
    "windows = []\n",
    "\n",
    "for doc_words in shuffle_doc_words_list:\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    length = len(words)\n",
    "    if length <= window_size:\n",
    "        windows.append(words)\n",
    "    else:\n",
    "        for j in range(length - window_size + 1):\n",
    "            window = words[j: j + window_size]\n",
    "            windows.append(window)\n",
    "\n",
    "\n",
    "word_window_freq = {}\n",
    "for window in windows:\n",
    "    appeared = set()\n",
    "    for i in range(len(window)):\n",
    "        if window[i] in appeared:\n",
    "            continue\n",
    "        if window[i] in word_window_freq:\n",
    "            word_window_freq[window[i]] += 1\n",
    "        else:\n",
    "            word_window_freq[window[i]] = 1\n",
    "        appeared.add(window[i])\n",
    "\n",
    "word_pair_count = {}\n",
    "for window in windows:\n",
    "    for i in range(1, len(window)):\n",
    "        for j in range(0, i):\n",
    "            word_i = window[i]\n",
    "            word_i_id = word_id_map[word_i]\n",
    "            word_j = window[j]\n",
    "            word_j_id = word_id_map[word_j]\n",
    "            if word_i_id == word_j_id:\n",
    "                continue\n",
    "            word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n",
    "            if word_pair_str in word_pair_count:\n",
    "                word_pair_count[word_pair_str] += 1\n",
    "            else:\n",
    "                word_pair_count[word_pair_str] = 1\n",
    "            # two orders\n",
    "            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n",
    "            if word_pair_str in word_pair_count:\n",
    "                word_pair_count[word_pair_str] += 1\n",
    "            else:\n",
    "                word_pair_count[word_pair_str] = 1\n",
    "\n",
    "row = []\n",
    "col = []\n",
    "weight = []\n",
    "\n",
    "num_window = len(windows)\n",
    "\n",
    "for key in word_pair_count:\n",
    "    temp = key.split(',')\n",
    "    i = int(temp[0])\n",
    "    j = int(temp[1])\n",
    "    count = word_pair_count[key]\n",
    "    word_freq_i = word_window_freq[vocab[i]]\n",
    "    word_freq_j = word_window_freq[vocab[j]]\n",
    "    pmi = log((1.0 * count / num_window) /\n",
    "              (1.0 * word_freq_i * word_freq_j/(num_window * num_window)))\n",
    "    if pmi <= 0:\n",
    "        continue\n",
    "    row.append(train_size + i)\n",
    "    col.append(train_size + j)\n",
    "    weight.append(pmi)\n",
    "\n",
    "doc_word_freq = {}\n",
    "\n",
    "for doc_id in range(len(shuffle_doc_words_list)):\n",
    "    doc_words = shuffle_doc_words_list[doc_id]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    for word in words:\n",
    "        word_id = word_id_map[word]\n",
    "        doc_word_str = str(doc_id) + ',' + str(word_id)\n",
    "        if doc_word_str in doc_word_freq:\n",
    "            doc_word_freq[doc_word_str] += 1\n",
    "        else:\n",
    "            doc_word_freq[doc_word_str] = 1\n",
    "\n",
    "for i in range(len(shuffle_doc_words_list)):\n",
    "    doc_words = shuffle_doc_words_list[i]\n",
    "    words = tokenizer.tokenize(doc_words)\n",
    "    doc_word_set = set()\n",
    "    for word in words:\n",
    "        if word in doc_word_set:\n",
    "            continue\n",
    "        j = word_id_map[word]\n",
    "        key = str(i) + ',' + str(j)\n",
    "        freq = doc_word_freq[key]\n",
    "        if i < train_size:\n",
    "            row.append(i)\n",
    "        else:\n",
    "            row.append(i + vocab_size)\n",
    "        col.append(train_size + j)\n",
    "        idf = log(1.0 * len(shuffle_doc_words_list) /\n",
    "                  word_doc_freq[vocab[j]])\n",
    "        weight.append(freq * idf)\n",
    "        doc_word_set.add(word)\n",
    "\n",
    "node_size = train_size + vocab_size + test_size\n",
    "adj = sp.csr_matrix(\n",
    "    (weight, (row, col)), shape=(node_size, node_size))\n",
    "\n",
    "f = open(\"data/ind.{}.x\".format(dataset), 'wb')\n",
    "pkl.dump(x, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.y\".format(dataset), 'wb')\n",
    "pkl.dump(y, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.test_x\".format(dataset), 'wb')\n",
    "pkl.dump(tx, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.test_y\".format(dataset), 'wb')\n",
    "pkl.dump(ty, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.all_x\".format(dataset), 'wb')\n",
    "pkl.dump(allx, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.all_y\".format(dataset), 'wb')\n",
    "pkl.dump(ally, f)\n",
    "f.close()\n",
    "\n",
    "f = open(\"data/ind.{}.adj\".format(dataset), 'wb')\n",
    "pkl.dump(adj, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5cf8754-0620-4acc-bb67-45bf2a08cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import log\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "dataset = 'yelp'\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "def load_data(dataset_str):\n",
    "    names = ['x', 'y', 'test_x', 'test_y', 'all_x', 'all_y', 'graph']\n",
    "    \n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, test_x, test_y, all_x, all_y, graph = tuple(objects)\n",
    "    test_idx_reorder = parse_index_file(\n",
    "        \"data/ind.{}.test.index\".format(dataset_str))\n",
    "    test_idx_range = np.sort(test_idx_reorder)\n",
    "    print(x.shape, y.shape, test_x.shape, test_y.shape, all_x.shape, all_y.shape)\n",
    "\n",
    "    features = sp.vstack((all_x, test_x)).tolil()\n",
    "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "    labels = np.vstack((all_y, test_y))\n",
    "    labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "    idx_test = test_idx_range.tolist()\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train, y_val, y_test = np.zeros(labels.shape), np.zeros(labels.shape), np.zeros(labels.shape)\n",
    "    \n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "\n",
    "def load_corpus(dataset_str):\n",
    "    names = ['x', 'y', 'test_x', 'test_y', 'all_x', 'all_y', 'adj']\n",
    "    \n",
    "    objects = []\n",
    "    for i in range(len(names)):\n",
    "        with open(\"data/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "            objects.append(pkl.load(f))\n",
    "\n",
    "    x, y, test_x, test_y, all_x, all_y, adj = tuple(objects)\n",
    "    print(x.shape, y.shape, test_x.shape, test_y.shape, all_x.shape, all_y.shape)\n",
    "\n",
    "    features = sp.vstack((all_x, test_x)).tolil()\n",
    "    labels = np.vstack((all_y, test_y))\n",
    "    print(len(labels))\n",
    "\n",
    "    train_idx_orig = parse_index_file(\n",
    "        \"data/{}.train.index\".format(dataset_str))\n",
    "    train_size = len(train_idx_orig)\n",
    "\n",
    "    val_size = train_size - x.shape[0]\n",
    "    test_size = test_x.shape[0]\n",
    "\n",
    "    idx_train = range(len(y))\n",
    "    idx_val = range(len(y), len(y) + val_size)\n",
    "    idx_test = range(all_x.shape[0], all_x.shape[0] + test_size)\n",
    "\n",
    "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "    y_train, y_val, y_test = np.zeros(labels.shape), np.zeros(labels.shape), np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "\n",
    "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "\n",
    "\n",
    "def preprocess_features(features):\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return sparse_to_tuple(features)\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858f8d7a-aa2b-4f85-b131-9b45dee460bb",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed39e50-365b-4fa9-8096-cdeab70e5a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data as Data\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from utils import *\n",
    "import dgl\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "import sys\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer, Engine\n",
    "from ignite.metrics import Accuracy, Loss, Metric\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.utils import manual_seed\n",
    "# from model import BertGCN\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from dgl import function as fn\n",
    "from dgl.base import DGLError\n",
    "from dgl.utils import expand_as_pair\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from dgl import function as fn\n",
    "from dgl.base import DGLError\n",
    "from dgl.utils import expand_as_pair\n",
    "from dgl.nn import GATConv\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "class BertClassifier(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model:str =\"roberta-base\", nb_class:int = 8):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.nb_class = nb_class\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.bert_model = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.feat_dim = list(self.bert_model.modules())[-2].out_features\n",
    "        self.classifier = torch.nn.Linear(self.feat_dim, nb_class)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        cls_feats = self.bert_model(input_ids, attention_mask)[0][:, 0]\n",
    "        cls_logit = self.classifier(cls_feats)\n",
    "        return cls_logit\n",
    "\n",
    "\n",
    "class BertGCN(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model:str =\"roberta-base\", nb_class:int = 2, ratio:float = 0.7, gcn_layers:int = 2, n_hidden:int = 200, dropout:int = 0.5):\n",
    "        super(BertGCN, self).__init__()\n",
    "        self.ratio = ratio\n",
    "        self.nb_class = nb_class\n",
    "        # self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "        self.tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "        self.bert_model = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.feat_dim = list(self.bert_model.modules())[-2].out_features\n",
    "        self.classifier = torch.nn.Linear(self.feat_dim, nb_class)\n",
    "        self.gcn = GCN(\n",
    "            in_feats=self.feat_dim,\n",
    "            n_hidden=n_hidden,\n",
    "            n_classes=nb_class,\n",
    "            n_layers=gcn_layers-1,\n",
    "            activation=F.elu,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, g, idx):\n",
    "        input_ids, attention_mask = g.ndata['input_ids'][idx], g.ndata['attention_mask'][idx]\n",
    "        if self.training:\n",
    "            cls_feats = self.bert_model(input_ids, attention_mask)[0][:, 0]\n",
    "            g.ndata['cls_feats'][idx] = cls_feats\n",
    "        else:\n",
    "            cls_feats = g.ndata['cls_feats'][idx]\n",
    "        cls_logit = self.classifier(cls_feats)\n",
    "        cls_pred = torch.nn.Softmax(dim=1)(cls_logit)\n",
    "        gcn_logit = self.gcn(g.ndata['cls_feats'], g, g.edata['edge_weight'])[idx]\n",
    "        gcn_pred = torch.nn.Softmax(dim=1)(gcn_logit)\n",
    "        pred = (gcn_pred+1e-10) * self.ratio + cls_pred * (1 - self.ratio)\n",
    "        pred = torch.log(pred)\n",
    "        return pred\n",
    "\n",
    "    \n",
    "class BertGAT(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model='roberta_base', nb_class=2, m=0.7, gcn_layers=2, heads=8, n_hidden=32, dropout=0.5):\n",
    "        super(BertGAT, self).__init__()\n",
    "        self.m = m\n",
    "        self.nb_class = nb_class\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "        self.bert_model = AutoModel.from_pretrained(pretrained_model)\n",
    "        self.feat_dim = list(self.bert_model.modules())[-2].out_features\n",
    "        self.classifier = torch.nn.Linear(self.feat_dim, nb_class)\n",
    "        self.gcn = GAT(\n",
    "                 num_layers=gcn_layers-1,\n",
    "                 in_dim=self.feat_dim,\n",
    "                 num_hidden=n_hidden,\n",
    "                 num_classes=nb_class,\n",
    "                 heads=[heads] * (gcn_layers-1) + [1],\n",
    "                 activation=F.elu,\n",
    "                 feat_drop=dropout,\n",
    "                 attn_drop=dropout,\n",
    "        )\n",
    "\n",
    "    def forward(self, g, idx):\n",
    "        input_ids, attention_mask = g.ndata['input_ids'][idx], g.ndata['attention_mask'][idx]\n",
    "        if self.training:\n",
    "            cls_feats = self.bert_model(input_ids, attention_mask)[0][:, 0]\n",
    "            g.ndata['cls_feats'][idx] = cls_feats\n",
    "        else:\n",
    "            cls_feats = g.ndata['cls_feats'][idx]\n",
    "        cls_logit = self.classifier(cls_feats)\n",
    "        cls_pred = torch.nn.Softmax(dim=1)(cls_logit)\n",
    "        gcn_logit = self.gcn(g.ndata['cls_feats'], g)[idx]\n",
    "        gcn_pred = torch.nn.Softmax(dim=1)(gcn_logit)\n",
    "        pred = (gcn_pred+1e-10) * self.m + cls_pred * (1 - self.m)\n",
    "        pred = torch.log(pred)\n",
    "        return pred    \n",
    "\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_layers,\n",
    "                 in_dim,\n",
    "                 num_hidden,\n",
    "                 num_classes,\n",
    "                 heads,\n",
    "                 activation,\n",
    "                 feat_drop=0,\n",
    "                 attn_drop=0,\n",
    "                 negative_slope=0.2,\n",
    "                 residual=False\n",
    "    ):\n",
    "        super(GAT, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.gat_layers = torch.nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        # input projection (no residual)\n",
    "        self.gat_layers.append(GATConv(\n",
    "            in_dim, num_hidden, heads[0],\n",
    "            feat_drop, attn_drop, negative_slope, False, self.activation))\n",
    "        # hidden layers\n",
    "        for l in range(1, num_layers):\n",
    "            # due to multi-head, the in_dim = num_hidden * num_heads\n",
    "            self.gat_layers.append(GATConv(\n",
    "                num_hidden * heads[l-1], num_hidden, heads[l],\n",
    "                feat_drop, attn_drop, negative_slope, residual, self.activation))\n",
    "        # output projection\n",
    "        self.gat_layers.append(GATConv(\n",
    "            num_hidden * heads[-2], num_classes, heads[-1],\n",
    "            feat_drop, attn_drop, negative_slope, residual, None))\n",
    "\n",
    "    def forward(self, inputs, g):\n",
    "        h = inputs\n",
    "        for l in range(self.num_layers):\n",
    "            h = self.gat_layers[l](g, h).flatten(1)\n",
    "        # output projection\n",
    "        logits = self.gat_layers[-1](g, h).mean(1)\n",
    "        return logits\n",
    "    \n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 normalization='none'):\n",
    "        super(GCN, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        self.layers.append(GraphConvEdgeWeight(in_feats, n_hidden, activation=activation, norm=normalization))\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(GraphConvEdgeWeight(n_hidden, n_hidden, activation=activation, norm=normalization))\n",
    "        self.layers.append(GraphConvEdgeWeight(n_hidden, n_classes, norm=normalization))\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features, g, edge_weight):\n",
    "        h = features\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layer(g, h, edge_weights=edge_weight)\n",
    "        return h\n",
    "    \n",
    "class GraphConvEdgeWeight(GraphConv):\n",
    "\n",
    "    def forward(self, graph, feat,  weight=None, edge_weights=None):\n",
    "        with graph.local_scope():\n",
    "            if not self._allow_zero_in_degree:\n",
    "                if (graph.in_degrees() == 0).any():\n",
    "                    raise DGLError('There are 0-in-degree nodes in the graph, '\n",
    "                                   'output for those nodes will be invalid. '\n",
    "                                   'This is harmful for some applications, '\n",
    "                                   'causing silent performance regression. '\n",
    "                                   'Adding self-loop on the input graph by '\n",
    "                                   'calling `g = dgl.add_self_loop(g)` will resolve '\n",
    "                                   'the issue. Setting ``allow_zero_in_degree`` '\n",
    "                                   'to be `True` when constructing this module will '\n",
    "                                   'suppress the check and let the code run.')\n",
    "\n",
    "            feat_src, feat_dst = expand_as_pair(feat, graph)\n",
    "            if self._norm == 'both':\n",
    "                degs = graph.out_degrees().float().clamp(min=1)\n",
    "                norm = torch.pow(degs, -0.5)\n",
    "                shp = norm.shape + (1,) * (feat_src.dim() - 1)\n",
    "                norm = torch.reshape(norm, shp)\n",
    "                feat_src = feat_src * norm\n",
    "\n",
    "            if weight is not None:\n",
    "                if self.weight is not None:\n",
    "                    raise DGLError('External weight is provided while at the same time the'\n",
    "                                   ' module has defined its own weight parameter. Please'\n",
    "                                   ' create the module with flag weight=False.')\n",
    "            else:\n",
    "                weight = self.weight\n",
    "\n",
    "            if self._in_feats > self._out_feats:\n",
    "                if weight is not None:\n",
    "                    feat_src = torch.matmul(feat_src, weight)\n",
    "                graph.srcdata['h'] = feat_src\n",
    "                if edge_weights is None:\n",
    "                    graph.update_all(fn.copy_src(src='h', out='m'),\n",
    "                                     fn.sum(msg='m', out='h'))\n",
    "                else:\n",
    "                    graph.edata['a'] = edge_weights\n",
    "                    graph.update_all(fn.u_mul_e('h', 'a', 'm'),\n",
    "                                     fn.sum(msg='m', out='h'))\n",
    "                rst = graph.dstdata['h']\n",
    "            else:\n",
    "                graph.srcdata['h'] = feat_src\n",
    "                if edge_weights is None:\n",
    "                    graph.update_all(fn.copy_src(src='h', out='m'),\n",
    "                                     fn.sum(msg='m', out='h'))\n",
    "                else:\n",
    "                    graph.edata['a'] = edge_weights\n",
    "                    graph.update_all(fn.u_mul_e('h', 'a', 'm'),\n",
    "                                     fn.sum(msg='m', out='h'))\n",
    "                rst = graph.dstdata['h']\n",
    "                if weight is not None:\n",
    "                    rst = torch.matmul(rst, weight)\n",
    "\n",
    "            if self._norm != 'none':\n",
    "                degs = graph.in_degrees().float().clamp(min=1)\n",
    "                if self._norm == 'both':\n",
    "                    norm = torch.pow(degs, -0.5)\n",
    "                else:\n",
    "                    norm = 1.0 / degs\n",
    "                shp = norm.shape + (1,) * (feat_dst.dim() - 1)\n",
    "                norm = torch.reshape(norm, shp)\n",
    "                rst = rst * norm\n",
    "\n",
    "            if self.bias is not None:\n",
    "                rst = rst + self.bias\n",
    "\n",
    "            if self._activation is not None:\n",
    "                rst = self._activation(rst)\n",
    "\n",
    "            return rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "875ed1ac-0b35-402a-9032-8181435cafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 51\n",
    "manual_seed(seed)\n",
    "max_length = 64\n",
    "batch_size = 256\n",
    "ratio = 0.1\n",
    "nb_epochs = 10\n",
    "dataset = 'yelp'\n",
    "n_hidden = 200\n",
    "dropout = 0.5\n",
    "gcn_lr = 1e-3\n",
    "bert_lr = 1e-5\n",
    "args = [max_length, batch_size, ratio, nb_epochs, dataset, n_hidden, dropout, gcn_lr, bert_lr, seed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef0ddd44-66f6-4b42-8ca1-934b8dea04a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:\n",
      "params:\n",
      "params:\n",
      "[64, 256, 0.1, 10, 'yelp', 200, 0.5, 0.001, 1e-05, 51]\n",
      "[64, 256, 0.1, 10, 'yelp', 200, 0.5, 0.001, 1e-05, 51]\n",
      "[64, 256, 0.1, 10, 'yelp', 200, 0.5, 0.001, 1e-05, 51]\n",
      "checkpoints path: ./checkpoint/robertagcn_yelp_0.1\n",
      "checkpoints path: ./checkpoint/robertagcn_yelp_0.1\n",
      "checkpoints path: ./checkpoint/robertagcn_yelp_0.1\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = './checkpoint/robertagcn_{}_{}'.format(dataset, ratio)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "streamhandle = logging.StreamHandler(sys.stdout)\n",
    "streamhandle.setFormatter(logging.Formatter('%(message)s'))\n",
    "streamhandle.setLevel(logging.INFO)\n",
    "\n",
    "filehandle = logging.FileHandler(filename=os.path.join(ckpt_dir, 'training.log'), mode='w')\n",
    "filehandle.setFormatter(logging.Formatter('%(message)s'))\n",
    "filehandle.setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('training logger')\n",
    "logger.addHandler(streamhandle)\n",
    "logger.addHandler(filehandle)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "cpu = torch.device('cpu')\n",
    "gpu = torch.device('cuda:0')\n",
    "\n",
    "logger.info('params:')\n",
    "logger.info(str(args))\n",
    "logger.info('checkpoints path: {}'.format(ckpt_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f11f40a6-e25e-480d-86c7-87732c91d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8654, 300) (8654, 2) (2404, 300) (2404, 2) (35868, 300) (35868, 2)\n",
      "38272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1355/3238164346.py:132: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.array(mask, dtype=np.bool)\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph information:\n",
      "graph information:\n",
      "graph information:\n",
      "Graph(num_nodes=38272, num_edges=24734470,\n",
      "      ndata_schemes={'input_ids': Scheme(shape=(64,), dtype=torch.int64), 'attention_mask': Scheme(shape=(64,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\n",
      "Graph(num_nodes=38272, num_edges=24734470,\n",
      "      ndata_schemes={'input_ids': Scheme(shape=(64,), dtype=torch.int64), 'attention_mask': Scheme(shape=(64,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\n",
      "Graph(num_nodes=38272, num_edges=24734470,\n",
      "      ndata_schemes={'input_ids': Scheme(shape=(64,), dtype=torch.int64), 'attention_mask': Scheme(shape=(64,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int64), 'train': Scheme(shape=(), dtype=torch.float32), 'val': Scheme(shape=(), dtype=torch.float32), 'test': Scheme(shape=(), dtype=torch.float32), 'label_train': Scheme(shape=(), dtype=torch.int64), 'cls_feats': Scheme(shape=(768,), dtype=torch.float32)}\n",
      "      edata_schemes={'edge_weight': Scheme(shape=(), dtype=torch.float32)})\n"
     ]
    }
   ],
   "source": [
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(dataset)\n",
    "\n",
    "nb_node = features.shape[0]\n",
    "nb_train, nb_val, nb_test = train_mask.sum(), val_mask.sum(), test_mask.sum()\n",
    "nb_word = nb_node - nb_train - nb_val - nb_test\n",
    "nb_class = y_train.shape[1]\n",
    "\n",
    "# model = BertGAT( pretrained_model='roberta-base', nb_class=2, m=0.7, gcn_layers=2, heads=8, n_hidden=32, dropout=0.5)\n",
    "# \n",
    "model = BertGCN(nb_class=nb_class, ratio=ratio, n_hidden=n_hidden, dropout=dropout)\n",
    "\n",
    "corpse_file = './data/corpus/' + dataset +'_shuffle.txt'\n",
    "with open(corpse_file, 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    text = text.replace('\\\\', '')\n",
    "    text = text.split('\\n')\n",
    "\n",
    "def encode_input(text, tokenizer):\n",
    "    input = tokenizer(text, max_length=max_length, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    return input.input_ids, input.attention_mask\n",
    "\n",
    "\n",
    "input_ids, attention_mask = encode_input(text, model.tokenizer)\n",
    "input_ids = torch.cat([input_ids[:-nb_test], torch.zeros((nb_word, max_length), dtype=torch.long), input_ids[-nb_test:]])\n",
    "attention_mask = torch.cat([attention_mask[:-nb_test], torch.zeros((nb_word, max_length), dtype=torch.long), attention_mask[-nb_test:]])\n",
    "\n",
    "y = y_train + y_test + y_val\n",
    "y_train = y_train.argmax(axis=1)\n",
    "y = y.argmax(axis=1)\n",
    "\n",
    "doc_mask  = train_mask + val_mask + test_mask\n",
    "\n",
    "adj_norm = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "g = dgl.from_scipy(adj_norm.astype('float32'), eweight_name='edge_weight')\n",
    "g.ndata['input_ids'], g.ndata['attention_mask'] = input_ids, attention_mask\n",
    "g.ndata['label'], g.ndata['train'], g.ndata['val'], g.ndata['test'] = \\\n",
    "    torch.LongTensor(y), torch.FloatTensor(train_mask), torch.FloatTensor(val_mask), torch.FloatTensor(test_mask)\n",
    "g.ndata['label_train'] = torch.LongTensor(y_train)\n",
    "g.ndata['cls_feats'] = torch.zeros((nb_node, model.feat_dim))\n",
    "\n",
    "logger.info('graph information:')\n",
    "logger.info(str(g))\n",
    "\n",
    "train_idx = Data.TensorDataset(torch.arange(0, nb_train, dtype=torch.long))\n",
    "val_idx = Data.TensorDataset(torch.arange(nb_train, nb_train + nb_val, dtype=torch.long))\n",
    "test_idx = Data.TensorDataset(torch.arange(nb_node-nb_test, nb_node, dtype=torch.long))\n",
    "doc_idx = Data.ConcatDataset([train_idx, val_idx, test_idx])\n",
    "\n",
    "idx_loader_train = Data.DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "idx_loader_val = Data.DataLoader(val_idx, batch_size=batch_size)\n",
    "idx_loader_test = Data.DataLoader(test_idx, batch_size=batch_size)\n",
    "idx_loader = Data.DataLoader(doc_idx, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7d52d5f-8eb3-4a5e-8f28-e6798d6e18f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(Metric):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.f1 = 0\n",
    "        self.count = 0\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output[0].detach(), output[1].detach()\n",
    "\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        f = f1_score(y.cpu(), predicted.cpu(), average='micro')\n",
    "        self.f1 += f\n",
    "        self.count += 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.f1 = 0\n",
    "        self.count = 0\n",
    "        super(F1Score, self).reset()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.f1 / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "811e6131-04c9-4a85-87e8-9f03af3abf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb \n",
    "\n",
    "def update_feature():\n",
    "    global model, g, doc_mask\n",
    "    dataloader = Data.DataLoader(\n",
    "        Data.TensorDataset(g.ndata['input_ids'][doc_mask], g.ndata['attention_mask'][doc_mask]),\n",
    "        batch_size=1024\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        model = model.to(gpu)\n",
    "        model.eval()\n",
    "        cls_list = []\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            input_ids, attention_mask = [x.to(gpu) for x in batch]\n",
    "            output = model.bert_model(input_ids=input_ids, attention_mask=attention_mask)[0][:, 0]\n",
    "            cls_list.append(output.cpu())\n",
    "        cls_feat = torch.cat(cls_list, axis=0)\n",
    "    g = g.to(cpu)\n",
    "    g.ndata['cls_feats'][doc_mask] = cls_feat\n",
    "    return g\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "        {'params': model.bert_model.parameters(), 'lr': bert_lr},\n",
    "        {'params': model.classifier.parameters(), 'lr': bert_lr},\n",
    "        {'params': model.gcn.parameters(), 'lr': gcn_lr},\n",
    "    ], lr=gcn_lr\n",
    ")\n",
    "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)\n",
    "\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    global model, g, optimizer\n",
    "    model.train()\n",
    "    model = model.to(gpu)\n",
    "    g = g.to(gpu)\n",
    "    optimizer.zero_grad()\n",
    "    # print(\"batch\",batch)\n",
    "    (idx, ) = [x.to(gpu) for x in batch]\n",
    "    optimizer.zero_grad()\n",
    "    train_mask = g.ndata['train'][idx].type(torch.BoolTensor)\n",
    "    y_pred = model(g, idx)[train_mask]\n",
    "    y_true = g.ndata['label_train'][idx][train_mask]\n",
    "    loss = F.nll_loss(y_pred, y_true)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    g.ndata['cls_feats'].detach_()\n",
    "    train_loss = loss.item()\n",
    "    with torch.no_grad():\n",
    "        if train_mask.sum() > 0:\n",
    "            y_true = y_true.detach().cpu()\n",
    "            y_pred = y_pred.argmax(axis=1).detach().cpu()\n",
    "            train_acc = accuracy_score(y_true, y_pred)\n",
    "        else:\n",
    "            train_acc = 1\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "trainer = Engine(train_step)\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(trainer)\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def reset_graph(trainer):\n",
    "    scheduler.step()\n",
    "    update_feature()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "count = 0 \n",
    "def test_step(engine, batch):\n",
    "    global model, g\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        model = model.to(gpu)\n",
    "        g = g.to(gpu)\n",
    "        (idx, ) = [x.to(gpu) for x in batch]\n",
    "        y_pred = model(g, idx)\n",
    "        y_true = g.ndata['label'][idx]\n",
    "        # wandb.init(project=\"embedding\")\n",
    "        wandb.init(settings=wandb.Settings(start_method=\"thread\"))\n",
    "\n",
    "\n",
    "        df_data = {\n",
    "                    'target':y_true.tolist(),\n",
    "                    'feature': y_pred.tolist()\n",
    "                }\n",
    "        df = pd.DataFrame(df_data)\n",
    "        wandb.log({\"Embedding\": df})\n",
    "        wandb.finish()\n",
    "         \n",
    "        return y_pred, y_true\n",
    "\n",
    "\n",
    "evaluator = Engine(test_step)\n",
    "eval_pbar = ProgressBar()\n",
    "eval_pbar.attach(evaluator)\n",
    "metrics={\n",
    "    'acc': Accuracy(),\n",
    "    'nll': Loss(torch.nn.NLLLoss()),\n",
    "    'f1' : F1Score()\n",
    "}\n",
    "for name, function in metrics.items():\n",
    "    function.attach(evaluator, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88855c8b-a30c-4e9e-8dba-b99e4344c86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.01434779167175293,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.01175832748413086,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.01242828369140625,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.010649681091308594,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.010669469833374023,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.010914802551269531,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.010354995727539062,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.011104583740234375,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.01143026351928711,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.011651754379272461,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 47,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/47]   2%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 470\n",
       "\tepoch: 10\n",
       "\tepoch_length: 47\n",
       "\tmax_epochs: 10\n",
       "\toutput: <class 'tuple'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "\n",
    "g = update_feature()\n",
    "trainer.run(idx_loader, max_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cb293-805f-48b0-b55b-b01e4975f70a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230713_235946-plkzao68</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/plkzao68' target=\"_blank\">soft-glitter-95</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/plkzao68' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/plkzao68</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-glitter-95</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/plkzao68' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/plkzao68</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230713_235946-plkzao68/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": "{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}<{remaining}]",
       "colour": null,
       "elapsed": 0.010948657989501953,
       "initial": 1,
       "n": 1,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 34,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ed589713664a478d24de7d60672d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/34]   3%|2          [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000009-l12tsqot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/l12tsqot' target=\"_blank\">clear-rain-96</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/l12tsqot' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/l12tsqot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">clear-rain-96</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/l12tsqot' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/l12tsqot</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000009-l12tsqot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40f5830285847ecbe4bee5ab05c6d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668460456033547, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000027-8xoq6m6j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8xoq6m6j' target=\"_blank\">azure-brook-97</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8xoq6m6j' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/8xoq6m6j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">azure-brook-97</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8xoq6m6j' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/8xoq6m6j</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000027-8xoq6m6j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f536731585475d94f621dee6c7641f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016672683600336313, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000044-jb8qy6x5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/jb8qy6x5' target=\"_blank\">toasty-pyramid-98</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/jb8qy6x5' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/jb8qy6x5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-pyramid-98</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/jb8qy6x5' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/jb8qy6x5</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000044-jb8qy6x5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ba8078f3824fd4b1f290bdf52522df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668427890787523, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000104-c2wm0yoq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/c2wm0yoq' target=\"_blank\">glorious-aardvark-99</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/c2wm0yoq' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/c2wm0yoq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-aardvark-99</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/c2wm0yoq' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/c2wm0yoq</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000104-c2wm0yoq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2904d6765ae43709c1a7e2f93daccb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666863610347112, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000121-v71hr1rg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/v71hr1rg' target=\"_blank\">electric-shadow-100</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/v71hr1rg' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/v71hr1rg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">electric-shadow-100</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/v71hr1rg' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/v71hr1rg</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000121-v71hr1rg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f698813222440e29aa944fe49bbc3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668345127254725, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000140-259gzz52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/259gzz52' target=\"_blank\">earnest-capybara-101</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/259gzz52' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/259gzz52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">earnest-capybara-101</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/259gzz52' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/259gzz52</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000140-259gzz52/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7613787def745cca59ab9edbaa4c677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668823516617217, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000156-8npv5q0k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8npv5q0k' target=\"_blank\">confused-field-102</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8npv5q0k' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/8npv5q0k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">confused-field-102</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/8npv5q0k' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/8npv5q0k</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000156-8npv5q0k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e92d4e9ecb34d9a9808e99959469e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667043222114444, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000221-xn7l9s2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/xn7l9s2u' target=\"_blank\">hardy-universe-103</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/xn7l9s2u' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/xn7l9s2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">hardy-universe-103</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/xn7l9s2u' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/xn7l9s2u</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000221-xn7l9s2u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61437b7b8df249d5960de7a36ac6884b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666831746697426, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000239-okb3ev5f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/okb3ev5f' target=\"_blank\">twilight-snowflake-104</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/okb3ev5f' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/okb3ev5f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">twilight-snowflake-104</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/okb3ev5f' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/okb3ev5f</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000239-okb3ev5f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713126a8790f42e3842497faded28ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0166693520732224, max=1.0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000255-heqaj67m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/heqaj67m' target=\"_blank\">stellar-snowflake-105</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/heqaj67m' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/heqaj67m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-snowflake-105</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/heqaj67m' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/heqaj67m</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000255-heqaj67m/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266ae3274f8741398dba05ac5062a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666854408880075, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000312-au6uynfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/au6uynfl' target=\"_blank\">glamorous-energy-106</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/au6uynfl' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/au6uynfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-energy-106</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/au6uynfl' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/au6uynfl</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000312-au6uynfl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1924f9c6e30f45e48e4b45b6e4d1cf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668582614511252, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000330-h0td2av1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/h0td2av1' target=\"_blank\">dauntless-flower-107</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/h0td2av1' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/h0td2av1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-flower-107</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/h0td2av1' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/h0td2av1</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000330-h0td2av1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02d1bda2e664338bca0f535e983bf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666829576715827, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000347-nc5r0f7p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/nc5r0f7p' target=\"_blank\">wise-lion-108</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/nc5r0f7p' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/nc5r0f7p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wise-lion-108</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/nc5r0f7p' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/nc5r0f7p</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000347-nc5r0f7p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667c7219f5dd4dad828c1a105634aba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668861483534178, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000404-ylla6j89</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/ylla6j89' target=\"_blank\">robust-plasma-109</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/ylla6j89' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/ylla6j89</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-plasma-109</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/ylla6j89' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/ylla6j89</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000404-ylla6j89/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c4692003de43c4b44858b40092b45a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668319484839836, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000420-degquz8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/degquz8c' target=\"_blank\">distinctive-monkey-110</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/degquz8c' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/degquz8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-monkey-110</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/degquz8c' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/degquz8c</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000420-degquz8c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630278bb298646679701d35620bd7302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668310947716238, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000441-62cs5ekc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/62cs5ekc' target=\"_blank\">bumbling-puddle-111</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/62cs5ekc' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/62cs5ekc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-puddle-111</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/62cs5ekc' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/62cs5ekc</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000441-62cs5ekc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f1ee86e9d74e9f9bafcd8ff05f46cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668676336606344, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000459-58xrcsft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/58xrcsft' target=\"_blank\">crimson-capybara-112</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/58xrcsft' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/58xrcsft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-capybara-112</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/58xrcsft' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/58xrcsft</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000459-58xrcsft/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7656c107c04c09bf2ab3c72616d61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668781700233618, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000520-n6dyybuj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/n6dyybuj' target=\"_blank\">radiant-elevator-113</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/n6dyybuj' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/n6dyybuj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">radiant-elevator-113</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/n6dyybuj' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/n6dyybuj</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000520-n6dyybuj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa18e25f40d49e9bdd5cdabedcbaa3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668611206114292, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000538-zo2elna1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/zo2elna1' target=\"_blank\">fast-serenity-114</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/zo2elna1' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/zo2elna1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-serenity-114</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/zo2elna1' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/zo2elna1</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000538-zo2elna1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e4ac677b1f436c91f46817a8e32fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668563367178042, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000557-lzdnz1b2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/lzdnz1b2' target=\"_blank\">glorious-microwave-115</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/lzdnz1b2' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/lzdnz1b2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-microwave-115</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/lzdnz1b2' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/lzdnz1b2</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000557-lzdnz1b2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a177ad54c02d42a1af3e3b8f54f85f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666893387834231, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000619-qeowniji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/qeowniji' target=\"_blank\">fine-eon-116</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/qeowniji' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/qeowniji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fine-eon-116</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/qeowniji' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/qeowniji</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000619-qeowniji/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc85f44696e640c896f0aa03c9604c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666860490416487, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000637-iibfyp2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/iibfyp2n' target=\"_blank\">wandering-microwave-117</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/iibfyp2n' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/iibfyp2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandering-microwave-117</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/iibfyp2n' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/iibfyp2n</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000637-iibfyp2n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b59c6212324c9ca8d1ea55f98aa196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669796810795865, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000653-b174w8lu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/b174w8lu' target=\"_blank\">likely-cloud-118</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/b174w8lu' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/b174w8lu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-cloud-118</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/b174w8lu' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/b174w8lu</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000653-b174w8lu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae45b5f49e647b8a854f4f09f8ddbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666854933525125, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000710-0ht25e0y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/0ht25e0y' target=\"_blank\">fancy-resonance-119</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/0ht25e0y' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/0ht25e0y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-resonance-119</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/0ht25e0y' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/0ht25e0y</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000710-0ht25e0y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bc2cbc8f3c49599acef4a79e53d8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669326927512884, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000727-w1n8muic</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/w1n8muic' target=\"_blank\">divine-field-120</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/w1n8muic' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/w1n8muic</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-field-120</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/w1n8muic' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/w1n8muic</a><br/>Synced 5 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000727-w1n8muic/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bfa8fdd57f458aac4a656182a81298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668949897090595, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nm6104054/nm6104054/comparedModel/wandb/run-20230714_000747-u07mglz5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/u07mglz5' target=\"_blank\">solar-shadow-121</a></strong> to <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/imhilaryy1999/uncategorized' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/u07mglz5' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/u07mglz5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-shadow-121</strong> at: <a href='https://wandb.ai/imhilaryy1999/uncategorized/runs/u07mglz5' target=\"_blank\">https://wandb.ai/imhilaryy1999/uncategorized/runs/u07mglz5</a><br/>Synced 6 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230714_000747-u07mglz5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df237923cd844fadba873c28dc47b609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668335689852636, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "evaluator.run(idx_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2cb76-a935-488b-a025-d8d1f95574aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_training_results(trainer):\n",
    "#     evaluator.run(idx_loader_train)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     train_acc, train_nll = metrics[\"acc\"], metrics[\"nll\"]\n",
    "#     evaluator.run(idx_loader_val)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     val_acc, val_nll, val_f1 = metrics[\"acc\"], metrics[\"nll\"], metrics[\"f1\"]\n",
    "#     evaluator.run(idx_loader_test)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     test_acc, test_nll, test_f1 = metrics[\"acc\"], metrics[\"nll\"], metrics[\"f1\"]\n",
    "#     logger.info(\n",
    "#         \"Epoch: {}  Train acc: {:.4f} loss: {:.4f}  Val acc: {:.4f} loss: {:.4f} f1: {:.4f}  Test acc: {:.4f} loss: {:.4f} f1: {:.4f}\"\n",
    "#         .format(trainer.state.epoch, train_acc, train_nll, \n",
    "#                 val_acc, val_nll, val_f1, \n",
    "#                 test_acc, test_nll, test_f1\n",
    "#                )\n",
    "#     )\n",
    "#     if test_f1 > log_training_results.best_test_f1 and test_f1 > 0.8712:\n",
    "#         logger.info(\"New checkpoint\")\n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 'bert_model': model.bert_model.state_dict(),\n",
    "#                 'classifier': model.classifier.state_dict(),\n",
    "#                 'gcn': model.gcn.state_dict(),\n",
    "#                 'optimizer': optimizer.state_dict(),\n",
    "#                 'epoch': trainer.state.epoch,\n",
    "#                 'seed':trainer.state.seed,\n",
    "#             },\n",
    "#             os.path.join(\n",
    "#                 ckpt_dir, 'checkpoint.pth'\n",
    "#             )\n",
    "#         )\n",
    "#         log_training_results.best_test_f1 = test_f1\n",
    "\n",
    "\n",
    "# log_training_results.best_test_f1 = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29e745ca-508e-40d0-b4c6-5b043dfd09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "# def log_training_results(trainer):\n",
    "#     evaluator.run(idx_loader_train)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     train_acc, train_nll = metrics[\"acc\"], metrics[\"nll\"]\n",
    "#     evaluator.run(idx_loader_val)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     val_acc, val_nll, val_f1 = metrics[\"acc\"], metrics[\"nll\"], metrics[\"f1\"]\n",
    "#     evaluator.run(idx_loader_test)\n",
    "#     metrics = evaluator.state.metrics\n",
    "#     test_acc, test_nll, test_f1 = metrics[\"acc\"], metrics[\"nll\"], metrics[\"f1\"]\n",
    "#     logger.info(\n",
    "#         \"Epoch: {}  Train acc: {:.4f} loss: {:.4f}  Val acc: {:.4f} loss: {:.4f} f1: {:.4f}  Test acc: {:.4f} loss: {:.4f} f1: {:.4f}\"\n",
    "#         .format(trainer.state.epoch, train_acc, train_nll, \n",
    "#                 val_acc, val_nll, val_f1, \n",
    "#                 test_acc, test_nll, test_f1\n",
    "#                )\n",
    "#     )\n",
    "#     if test_f1 > log_training_results.best_test_f1 and test_f1 > 0.8712:\n",
    "#         logger.info(\"New checkpoint\")\n",
    "#         torch.save(\n",
    "#             {\n",
    "#                 'bert_model': model.bert_model.state_dict(),\n",
    "#                 'classifier': model.classifier.state_dict(),\n",
    "#                 'gcn': model.gcn.state_dict(),\n",
    "#                 'optimizer': optimizer.state_dict(),\n",
    "#                 'epoch': trainer.state.epoch,\n",
    "#                 'seed':trainer.state.seed,\n",
    "#             },\n",
    "#             os.path.join(\n",
    "#                 ckpt_dir, 'checkpoint.pth'\n",
    "#             )\n",
    "#         )\n",
    "#         log_training_results.best_test_f1 = test_f1\n",
    "\n",
    "\n",
    "# log_training_results.best_test_f1 = 0\n",
    "# g = update_feature()\n",
    "# trainer.run(idx_loader, max_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c4d5774-e8a4-4401-b567-50a1adae6ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,  7761,  6821,  ...,  3714, 11540,     2],\n",
      "        [    0,  7761,   385,  ...,  3137,    36,     2],\n",
      "        [    0,  7761,    40,  ...,  8493,   155,     2],\n",
      "        ...,\n",
      "        [    0,  7761,   475,  ...,  1115,   338,     2],\n",
      "        [    0,  7761,  1236,  ...,   257,    36,     2],\n",
      "        [    0,  7761,  7321,  ...,  1153,   206,     2]], device='cuda:0')\n",
      "tensor([[    0,  7761, 13145,  ...,  8060,   295,     2],\n",
      "        [    0,  7761, 45584,  ...,   910, 28024,     2],\n",
      "        [    0,  7761,  3778,  ...,   257,   875,     2],\n",
      "        ...,\n",
      "        [    0,  7761,  6821,  ...,  2527,  1717,     2],\n",
      "        [    0,  7761,  3553,  ...,   260,  1891,     2],\n",
      "        [    0,  7761,  2242,  ...,   475, 10570,     2]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dataloader = Data.DataLoader(\n",
    "    Data.TensorDataset(g.ndata['input_ids'][doc_mask], g.ndata['attention_mask'][doc_mask]),\n",
    "    batch_size=1024\n",
    ")\n",
    "for i, batch in enumerate(dataloader):\n",
    "    input_ids, attention_mask = [x.to(gpu) for x in batch]\n",
    "    print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76fe6205-13cf-4bf8-8aca-f3e079730417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94dcba67-f312-41de-ab47-d7ab60ca4496",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m cls_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idx_loader_train):\n\u001b[0;32m---> 18\u001b[0m     idx, attention_mask \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(gpu) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     19\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(gpu)\n\u001b[1;32m     20\u001b[0m     g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mto(gpu)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "global model, g , doc_mask\n",
    "# dataloader = Data.DataLoader(\n",
    "#     Data.TensorDataset(g.ndata['input_ids'][doc_mask], g.ndata['attention_mask'][doc_mask]),\n",
    "    \n",
    "#     batch_size=1024\n",
    "# )\n",
    "\n",
    "idx_loader_train = Data.DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    global model, g \n",
    "    model.eval()\n",
    "    model = model.to(gpu)\n",
    "    \n",
    "    g = g.to(gpu)\n",
    "    cls_list = []\n",
    "    for i, batch in enumerate(idx_loader_train):\n",
    "        idx, attention_mask = [x.to(gpu) for x in batch]\n",
    "        model = model.to(gpu)\n",
    "        g = g.to(gpu)\n",
    "        # (idx, ) = [x.to(gpu) for x in batch]\n",
    "        print(g,np.shape(idx))\n",
    "        y_pred = model(g, idx)\n",
    "        y_true = g.ndata['label'][idx]\n",
    "        \n",
    "        df_data = {\n",
    "                    'target':y_true.to_lost(),\n",
    "                    'feature': y_pred.to_lost()\n",
    "                }\n",
    "        df = pd.DataFrame(df_data)\n",
    "        wandb.log({\"Embedding\": df})\n",
    "        wandb.finish()\n",
    "        \n",
    "        \n",
    "        # y_pred = model(g, idx)\n",
    "        # y_true = g.ndata['label'][idx]\n",
    "        # y = y_true.tolist()\n",
    "        # # output = model(features, adj)\n",
    "        # wandb.init(project=\"embedding_3\")\n",
    "        # # out = output[idx_train].tolist()\n",
    "        # out = y_pred.tolist()\n",
    "        # df_data = {\n",
    "        #             'target':y,\n",
    "        #             'feature': out\n",
    "        #         }\n",
    "        # df = pd.DataFrame(df_data)\n",
    "        # wandb.log({\"Embedding\": df})\n",
    "        # wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468513e-ddb9-4056-9043-2f0fb3bc3df9",
   "metadata": {},
   "source": [
    "# BERTGAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff356f3a-691d-47c1-ad22-996527e7fcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
